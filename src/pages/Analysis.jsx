import { useEffect, useRef, useState } from 'react'

import IntroImage from '@/assets/images/home_pogny.png' // ì¸íŠ¸ë¡œ ì´ë¯¸ì§€
import { fetchData } from '@/lib/api/util' // fetchData ìœ í‹¸ í•¨ìˆ˜
import { useNavigate } from 'react-router-dom'
import axios from 'axios'

const fetchQuestionFromGPT = async () => {
    const apiKey = import.meta.env.VITE_OPENAI_API_KEY

    try {
        const response = await axios.post(
            'https://api.openai.com/v1/chat/completions',
            {
                model: 'gpt-3.5-turbo',
                messages: [
                    {
                        role: 'system',
                        content: `ë‹¹ì‹ ì€ í•œêµ­ ë…¸ì¸ì„ ìœ„í•œ ì¸ì§€ ëŠ¥ë ¥ í‰ê°€ ì§ˆë¬¸ì„ ë§Œë“œëŠ” ì „ë¬¸ AI ë„ìš°ë¯¸ì…ë‹ˆë‹¤. 
                        ë‹¤ìŒ ì¡°ê±´ì„ ì¶©ì¡±í•˜ëŠ” í•œ ê°œì˜ ëª…í™•í•˜ê³  ê°„ë‹¨í•œ ì§ˆë¬¸ì„ í•œêµ­ì–´ë¡œ ìƒì„±í•´ ì£¼ì„¸ìš”:
                        - ë…¸ì¸ì´ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆëŠ” ì–¸ì–´ë¡œ ì‘ì„±
                        - ê¸°ì–µë ¥, ì¸ì§€ ëŠ¥ë ¥, ì¼ìƒ ê¸°ëŠ¥ì„ í‰ê°€í•˜ëŠ” ì§ˆë¬¸
                        - ê°„ë‹¨í•˜ê³  ëª…í™•í•˜ê²Œ ëŒ€ë‹µí•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸
                        - í•œêµ­ ë¬¸í™”ì™€ ë…¸ì¸ì˜ ìƒí™œ ë§¥ë½ì— ì í•©í•œ ì§ˆë¬¸
                        ì¶”ê°€ ì„¤ëª… ì—†ì´ ì˜¤ì§ ì§ˆë¬¸ë§Œ ì œê³µí•´ ì£¼ì„¸ìš”.`
                    },
                    {
                        role: 'user',
                        content: 'ë…¸ì¸ì˜ ì¸ì§€ ê¸°ëŠ¥ì„ í‰ê°€í•  ìˆ˜ ìˆëŠ” ì§„ë‹¨ ì§ˆë¬¸ì„ ìƒì„±í•´ ì£¼ì„¸ìš”.'
                    }
                ],
                max_tokens: 50,
                temperature: 0.7
            },
            {
                headers: {
                    'Content-Type': 'application/json',
                    Authorization: `Bearer ${apiKey}`
                }
            }
        )

        return response.data.choices[0].message.content.trim()
    } catch (error) {
        console.error('GPT ì§ˆë¬¸ ìƒì„± ì˜¤ë¥˜:', error)
        throw error
    }
}

const analyzeAnswerWithGPT = async (question, userAnswer) => {
    const apiKey = import.meta.env.VITE_OPENAI_API_KEY

    try {
        const response = await axios.post(
            'https://api.openai.com/v1/chat/completions',
            {
                model: 'gpt-4-0613',
                messages: [
                    {
                        role: 'system',
                        content: `ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ í‰ê°€í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
                        ë‹¤ìŒ ë‚´ìš©ì„ ë¶„ì„í•˜ì„¸ìš”:
                        - ë‹µë³€ì˜ ì ì ˆì„± ("ì ì ˆí•¨" ë˜ëŠ” "ë¶€ì ì ˆí•¨"ìœ¼ë¡œ í‰ê°€)
                        - í‰ê°€ ê·¼ê±°ë¥¼ ê°„ë‹¨íˆ ì„¤ëª….
                        ê²°ê³¼ëŠ” JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”:
                        {
                            "ì ì ˆì„±": "ì ì ˆí•¨" ë˜ëŠ” "ë¶€ì ì ˆí•¨",
                            "ì´ìœ ": "í‰ê°€ ê·¼ê±°"
                        }`
                    },
                    {
                        role: 'user',
                        content: `ì§ˆë¬¸: ${question}\në‹µë³€: ${userAnswer}`
                    }
                ],
                max_tokens: 100,
                temperature: 0.7
            },
            {
                headers: {
                    'Content-Type': 'application/json',
                    Authorization: `Bearer ${apiKey}`
                }
            }
        )

        return JSON.parse(response.data.choices[0].message.content.trim())
    } catch (error) {
        console.error('ë‹µë³€ ë¶„ì„ ì˜¤ë¥˜:', error)
        return {
            ì ì ˆì„±: 'ì˜¤ë¥˜',
            ì´ìœ : 'ë¶„ì„ ì‹¤íŒ¨'
        }
    }
}

const VoiceChat = () => {
    const navigate = useNavigate() // í˜ì´ì§€ ì´ë™ì„ ìœ„í•œ useNavigate í›…
    const [currentStep, setCurrentStep] = useState(0)
    const [recognition, setRecognition] = useState(null)
    const [currentAnswer, setCurrentAnswer] = useState(null)
    const [status, setStatus] = useState({ message: 'ì‹œì‘ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”', type: 'normal' })
    const [isStarted, setIsStarted] = useState(false)
    const [responses, setResponses] = useState([])
    const [isFinished, setIsFinished] = useState(false)
    const [errorMsg, setErrorMsg] = useState('')
    const [isIntroStep, setIsIntroStep] = useState(true) // ì‹œì‘ ë‹¨ê³„ ìƒíƒœ
    const [questions, setQuestions] = useState([])
    const [isLoading, setIsLoading] = useState(false)
    const [evaluations, setEvaluations] = useState([]) // ë‹µë³€ í‰ê°€ ë°ì´í„°ë¥¼ ì €ì¥

    const videoRef = useRef(null)

    const generateQuestions = async () => {
        setIsLoading(true)
        setQuestions([])

        try {
            const questionPromises = [
                fetchQuestionFromGPT(),
                fetchQuestionFromGPT(),
                fetchQuestionFromGPT()
            ]

            console.log('Fetching questions...') // ë¡œê¹… ì¶”ê°€
            const generatedQuestions = await Promise.all(questionPromises)

            console.log('Generated Questions:', generatedQuestions) // ìƒì„±ëœ ì§ˆë¬¸ ë¡œê¹…
            setQuestions(generatedQuestions)
        } catch (error) {
            console.error('ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨:', error)
            console.error('Error Details:', error.response?.data || error.message) // ìƒì„¸ ì˜¤ë¥˜ ë¡œê¹…
        } finally {
            setIsLoading(false)
        }
    }

    const startConversation = async () => {
        try {
            await generateQuestions()
            setResponses([])
            setEvaluations([])
            setCurrentStep(0)
            setCurrentAnswer(null)
            setIsStarted(true)
            setIsFinished(false)

            const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
            stream.getTracks().forEach(track => track.stop())

            await startQuestion(0)
        } catch (error) {
            console.error('Conversation error:', error)
            updateStatus(`ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${error.message}`, 'error')
            setIsStarted(false)
        }
    }

    const startQuestion = async stepIndex => {
        try {
            const startImage = captureImage() // ì§ˆë¬¸ ì‹œì‘ ì‹œ ì´ë¯¸ì§€ ìº¡ì²˜
            await sendImageToServer(startImage, stepIndex + 1) // ì‹œì‘ ì´ë¯¸ì§€ ì „ì†¡

            await speak(questions[stepIndex])
            await listen()

            const endImage = captureImage() // ì§ˆë¬¸ ëë‚  ë•Œ ì´ë¯¸ì§€ ìº¡ì²˜
            await sendImageToServer(endImage, stepIndex + 1) // ë ì´ë¯¸ì§€ ì „ì†¡
        } catch (error) {
            console.error('Question error:', error)
        }
    }

    const handleNextQuestion = async () => {
        stopRecognition()

        if (currentAnswer) {
            const question = questions[currentStep]
            const evaluation = await analyzeAnswerWithGPT(question, currentAnswer)
            setResponses(prev => [
                ...prev,
                {
                    question: questions[currentStep],
                    answer: currentAnswer
                }
            ])
            setEvaluations(prev => [...prev, evaluation])
            setCurrentAnswer(null)
        }

        if (currentStep < questions.length - 1) {
            setCurrentStep(prev => prev + 1)
            await startQuestion(currentStep + 1)
        } else {
            updateStatus('ëª¨ë“  ëŒ€í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.', 'success')
            setIsFinished(true)
            setIsStarted(false)
        }
    }

    const startCamera = async () => {
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
            setErrorMsg('ì´ ë¸Œë¼ìš°ì €ëŠ” ì¹´ë©”ë¼ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.')
            console.error('mediaDevices ë˜ëŠ” getUserMediaê°€ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.')
            return
        }

        try {
            const stream = await navigator.mediaDevices.getUserMedia({
                video: true,
                audio: false
            })
            if (videoRef.current) {
                videoRef.current.srcObject = stream
                setErrorMsg('')
            }
        } catch (error) {
            if (error.name === 'NotAllowedError') {
                setErrorMsg('ì¹´ë©”ë¼ ì ‘ê·¼ì´ í—ˆìš©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
            } else if (error.name === 'NotFoundError') {
                setErrorMsg('ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ê°€ ì—†ìŠµë‹ˆë‹¤.')
            } else {
                setErrorMsg('ì¹´ë©”ë¼ ì ‘ê·¼ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.')
            }
            console.error('ì¹´ë©”ë¼ ì—ëŸ¬:', error)
        }
    }

    const stopCamera = () => {
        if (videoRef.current?.srcObject) {
            const tracks = videoRef.current.srcObject.getTracks()
            tracks.forEach(track => track.stop())
            videoRef.current.srcObject = null
        }
    }

    useEffect(() => {
        if (!isIntroStep) {
            startCamera()
        }
        return () => {
            stopCamera()
        }
    }, [isIntroStep])

    useEffect(() => {
        if (isFinished) {
            stopCamera()
        }
    }, [isFinished])

    const updateStatus = (message, type = 'normal', isListening = false) => {
        setStatus({ message, type, isListening })
    }

    const speak = text => {
        return new Promise(resolve => {
            const utterance = new SpeechSynthesisUtterance(text)
            utterance.lang = 'ko-KR'
            utterance.onend = resolve
            updateStatus(`ğŸ”Š ë§í•˜ëŠ” ì¤‘: ${text}`)
            speechSynthesis.speak(utterance)
        })
    }

    const stopRecognition = () => {
        if (recognition) {
            recognition.stop()
            setRecognition(null)
        }
    }

    const listen = async () => {
        stopRecognition()

        return new Promise((resolve, reject) => {
            try {
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition
                const newRecognition = new SpeechRecognition()
                newRecognition.lang = 'ko-KR'
                newRecognition.interimResults = false
                newRecognition.maxAlternatives = 1

                let isAnswered = false

                newRecognition.onstart = () => {
                    updateStatus('ğŸ¤ ë“£ê³  ìˆìŠµë‹ˆë‹¤...', 'normal', true)
                }

                newRecognition.onresult = event => {
                    const text = event.results[0][0].transcript
                    if (text.trim()) {
                        setCurrentAnswer(text)
                        isAnswered = true
                        updateStatus('ë‹µë³€ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.', 'success')
                        resolve(text)
                    } else {
                        handleNoSpeech()
                        reject(new Error('ìŒì„±ì´ ì¸ì‹ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤'))
                    }
                }

                newRecognition.onerror = event => {
                    handleNoSpeech()
                    reject(new Error(`ìŒì„± ì¸ì‹ ì˜¤ë¥˜: ${event.error}`))
                }

                newRecognition.onend = () => {
                    if (!isAnswered) {
                        handleNoSpeech()
                    }
                }

                setRecognition(newRecognition)
                newRecognition.start()
            } catch (err) {
                reject(new Error('ìŒì„± ì¸ì‹ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤'))
            }
        })
    }

    const handleNoSpeech = () => {
        updateStatus('ë‹µë³€ì´ ì •í™•íˆ ì¸ì‹ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.', 'error')
    }

    const retry = async () => {
        setCurrentAnswer(null)
        updateStatus('ë‹¤ì‹œ ë‹µë³€ì„ ì‹œë„í•©ë‹ˆë‹¤.')
        await listen()
    }

    const captureImage = () => {
        if (!videoRef.current) return null

        const canvas = document.createElement('canvas')
        canvas.width = videoRef.current.videoWidth
        canvas.height = videoRef.current.videoHeight

        const context = canvas.getContext('2d')
        context.drawImage(videoRef.current, 0, 0, canvas.width, canvas.height)

        return canvas.toDataURL('image/jpeg') // Base64ë¡œ ë³€í™˜
    }

    const sendImageToServer = async (image, count) => {
        try {
            const userId = localStorage.getItem('userId') // ë¡œì»¬ìŠ¤í† ë¦¬ì§€ì—ì„œ userId ê°€ì ¸ì˜¤ê¸°
            const url = `${import.meta.env.VITE_API_URL}/analyze`

            const response = await fetchData({
                url,
                method: 'POST',
                body: {
                    image,
                    count: 1, // í•­ìƒ 1ë¡œ ê³ ì •
                    userId
                }
            })

            console.log('Server response:', response)
        } catch (error) {
            console.error('Error sending image to server:', error)
        }
    }

    if (isIntroStep) {
        return (
            <div className="w-full h-screen flex flex-col justify-center items-center px-4">
                {' '}
                {/* ì–‘ìª½ íŒ¨ë”© ì¶”ê°€ */}
                <h1 className="text-2xl font-bold mb-8 text-gray-800">í¬ê·¼ì´ì™€ ëŒ€í™”í•˜ê¸°</h1>
                <img
                    src={IntroImage} // ì ì ˆí•œ ì´ë¯¸ì§€ ê²½ë¡œë¡œ ëŒ€ì²´í•˜ì„¸ìš”.
                    alt="ì¸ì§€ëŠ¥ë ¥ í…ŒìŠ¤íŠ¸"
                    className="w-[300px] h-[300px] mb-8"
                />
                <button
                    onClick={() => setIsIntroStep(false)}
                    className="w-full max-w-3xl bg-blue-600 text-white px-6 py-3 rounded-lg hover:bg-blue-700 transition">
                    ì‹œì‘í•˜ê¸°
                </button>
            </div>
        )
    }

    if (isFinished) {
        return (
            <div className="w-full h-screen flex justify-center items-center">
                <div className="w-full max-w-3xl p-6 bg-white rounded-lg">
                    <h1 className="text-2xl font-bold mb-4 text-center">ëŒ€í™” ê²°ê³¼</h1>
                    {responses.map((response, index) => (
                        <div
                            key={index}
                            className="my-4 p-4 bg-gray-100 rounded-lg">
                            <div className="font-bold text-gray-600">Q: {response.question}</div>
                            <div className="text-gray-800 mt-1">A: {response.answer}</div>
                            <p>
                                <strong>í‰ê°€:</strong> {evaluations[index]?.ì ì ˆì„± || 'ë¶„ì„ ì¤‘'}
                            </p>
                            <p>
                                <strong>ì´ìœ :</strong> {evaluations[index]?.ì´ìœ  || 'ë¶„ì„ ì¤‘'}
                            </p>
                        </div>
                    ))}
                    <button
                        onClick={() => navigate('/mypage')} // /mypageë¡œ ì´ë™
                        className="w-full py-3 mt-6 bg-indigo-500 text-white rounded-lg hover:bg-indigo-600 transition">
                        ë” ìì„¸í•œ ê²°ê³¼ ë³´ê¸°
                    </button>
                    <button
                        onClick={startConversation}
                        className="w-full py-3 mt-6 bg-blue-600 text-white rounded-lg hover:bg-blue-700 transition">
                        ë‹¤ì‹œ ì‹œì‘í•˜ê¸°
                    </button>
                </div>
            </div>
        )
    }

    return (
        <div className="w-full h-screen flex flex-col">
            {/* Progress bar */}
            <div className="w-full max-w-3xl bg-gray-200 h-2 mt-4 mx-auto rounded">
                <div
                    className="bg-blue-600 h-2 rounded transition-all duration-300"
                    style={{ width: `${((currentStep + 1) / questions.length) * 100}%` }}></div>
            </div>

            {/* ìƒë‹¨ìœ¼ë¡œ ì˜¬ë¦° ì„¹ì…˜ */}
            <div className="flex flex-col justify-start items-center flex-grow pt-4 px-4">
                <p className="text-center text-black text-base mb-3">{questions[currentStep]}</p>
                {/* ìƒíƒœ ë©”ì‹œì§€ */}
                <div
                    className={`text-center p-4 rounded w-full max-w-3xl ${
                        status.type === 'error'
                            ? 'bg-red-100 text-red-600'
                            : status.type === 'success'
                              ? 'bg-green-100 text-green-600'
                              : 'bg-gray-100 text-gray-800'
                    }`}>
                    {status.message}
                </div>

                {/* ì§ˆë¬¸ê³¼ ë²„íŠ¼ */}
                <div className="w-full max-w-3xl p-4 bg-white rounded-lg">
                    {/* ì§ˆë¬¸ê³¼ ë‹¨ê³„ í‘œì‹œ */}
                    <div className="flex justify-between items-center pb-2 mb-2">
                        <h1 className="text-lg font-bold">ìŒì„± ëŒ€í™” í…ŒìŠ¤íŠ¸</h1>
                        <div className="text-sm">
                            {currentStep + 1} / {questions.length}
                        </div>
                    </div>

                    {/* ëŒ€í™” ì‹œì‘ ë²„íŠ¼ */}
                    {!isStarted ? (
                        <button
                            onClick={startConversation}
                            className="w-full py-2 mb-3 bg-black text-white rounded-lg hover:opacity-90 transition">
                            {isLoading ? 'ì§ˆë¬¸ ìƒì„± ì¤‘...' : 'ëŒ€í™” ì‹œì‘'}
                        </button>
                    ) : (
                        <>
                            {/* í˜„ì¬ ì§ˆë¬¸ */}
                            <p className="text-center text-base mb-3">{questions[currentStep]}</p>

                            {/* ë‹¤ì‹œ ë‹µë³€í•˜ê¸° ë²„íŠ¼ */}
                            {!currentAnswer && (
                                <button
                                    onClick={retry}
                                    className="w-full py-2 mb-3 bg-red-600 text-white rounded-lg hover:opacity-90 transition">
                                    ë‹¤ì‹œ ë‹µë³€í•˜ê¸°
                                </button>
                            )}

                            {/* ë‹¤ìŒ ì§ˆë¬¸ / ê²°ê³¼ ë²„íŠ¼ */}
                            <button
                                onClick={handleNextQuestion}
                                className={`w-full py-2 ${
                                    currentStep === questions.length - 1
                                        ? 'bg-green-600 hover:opacity-90'
                                        : 'bg-blue-600 hover:opacity-90'
                                } text-white rounded-lg transition`}>
                                {currentStep === questions.length - 1
                                    ? 'ê²°ê³¼ ë³´ê¸°'
                                    : 'ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ'}
                            </button>
                        </>
                    )}
                </div>

                {/* ë¹„ë””ì˜¤ ì˜ì—­ */}
                <div className="relative bg-gray-100 rounded-lg overflow-hidden mt-4 w-full max-w-3xl">
                    {errorMsg && (
                        <div className="absolute inset-0 flex items-center justify-center text-red-500">
                            {errorMsg}
                        </div>
                    )}
                    <video
                        ref={videoRef}
                        className="w-full h-[400px] object-cover transform scale-x-[-1]"
                        autoPlay
                        playsInline
                    />
                </div>
            </div>
        </div>
    )
}

export default VoiceChat
